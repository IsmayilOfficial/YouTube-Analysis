knitr::opts_chunk$set(echo = TRUE)
library(tuber)
app_id = '513902774051-nfunqdrtndpb7jkp1t069rbcut20vif6.apps.googleusercontent.com'
app_secret = '1Tw5Sv95wRU1K5zV3FiwMfLG'
# establishing connecting with YouTube
# credentials
yt_oauth(app_id = app_id, app_secret = app_secret)
videos_year <- yt_search(term = "new gadgets ",published_after = "2000-1-01T00:00:00Z", published_before = "2020-1-1T00:00:00Z")
videostats = lapply(as.character(videos_year$video_id), function(x){
get_stats(video_id = x)
})
library(plyr)
df = ldply(videostats, data.frame)
# merging videos stats with the main file:  videos_year
colnames(df)[1] = 'video_id' # renaming 'id' as video_id so that it matches same coluimn in main table
library(dplyr)
videos_year = videos_year %>% left_join(df, by = 'video_id')
# correcting data type
videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')]=apply(videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')],2,as.numeric)
# converting into data type 'date'
videos_year$publishedAt = as.Date(videos_year$publishedAt)
str(videos_year$publishedAt)
#install.packages("lubridate")
library(lubridate)
# creating new variables 'year' and 'month'
videos_year = videos_year %>% mutate(month = month(publishedAt)) %>% mutate(year = year(publishedAt))
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
#install.packages("factoextra")
library(factoextra) # clustering algorithms & visualization
# cleaning video titles
videos_year$title= gsub("<.*?>","", videos_year$title) #removing html tags
videos_year$title= gsub("[[:punct:]]", " ", videos_year$title) #removing html tags
videos_year$title = gsub("[ |\t]{2,}", " ", videos_year$title)  # Remove tabs
videos_year$title = gsub("^ ", "", videos_year$title)  # Leading blanks
videos_year$title = gsub(" $", "", videos_year$title)  # Lagging blanks
videos_year$title = gsub(" +", " ", videos_year$title) # General spaces
videos_year$title = tolower(videos_year$title) # lowering all letters
write.csv(videos_year,'new_gadgets.csv', row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
#
library(tuber)
app_id = '513902774051-nfunqdrtndpb7jkp1t069rbcut20vif6.apps.googleusercontent.com'
app_secret = '1Tw5Sv95wRU1K5zV3FiwMfLG'
# establishing connecting with YouTube
# credentials
yt_oauth(app_id = app_id, app_secret = app_secret)
videos_year <- yt_search(term = "cat")
videostats = lapply(as.character(videos_year$video_id), function(x){
get_stats(video_id = x)
})
library(plyr)
df = ldply(videostats, data.frame)
# merging videos stats with the main file:  videos_year
colnames(df)[1] = 'video_id' # renaming 'id' as video_id so that it matches same coluimn in main table
library(dplyr)
videos_year = videos_year %>% left_join(df, by = 'video_id')
# correcting data type
videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')]=apply(videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')],2,as.numeric)
# converting into data type 'date'
videos_year$publishedAt = as.Date(videos_year$publishedAt)
str(videos_year$publishedAt)
#install.packages("lubridate")
library(lubridate)
# creating new variables 'year' and 'month'
videos_year = videos_year %>% mutate(month = month(publishedAt)) %>% mutate(year = year(publishedAt))
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
#install.packages("factoextra")
library(factoextra) # clustering algorithms & visualization
# cleaning video titles
videos_year$title= gsub("<.*?>","", videos_year$title) #removing html tags
videos_year$title= gsub("[[:punct:]]", " ", videos_year$title) #removing html tags
videos_year$title = gsub("[ |\t]{2,}", " ", videos_year$title)  # Remove tabs
videos_year$title = gsub("^ ", "", videos_year$title)  # Leading blanks
videos_year$title = gsub(" $", "", videos_year$title)  # Lagging blanks
videos_year$title = gsub(" +", " ", videos_year$title) # General spaces
videos_year$title = tolower(videos_year$title) # lowering all letters
write.csv(videos_year,'cat.csv', row.names = FALSE)
videos_year <- yt_search(term = "dog")
videostats = lapply(as.character(videos_year$video_id), function(x){
get_stats(video_id = x)
})
library(plyr)
df = ldply(videostats, data.frame)
# merging videos stats with the main file:  videos_year
colnames(df)[1] = 'video_id' # renaming 'id' as video_id so that it matches same coluimn in main table
library(dplyr)
videos_year = videos_year %>% left_join(df, by = 'video_id')
# correcting data type
videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')]=apply(videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')],2,as.numeric)
# converting into data type 'date'
videos_year$publishedAt = as.Date(videos_year$publishedAt)
str(videos_year$publishedAt)
#install.packages("lubridate")
library(lubridate)
# creating new variables 'year' and 'month'
videos_year = videos_year %>% mutate(month = month(publishedAt)) %>% mutate(year = year(publishedAt))
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
#install.packages("factoextra")
library(factoextra) # clustering algorithms & visualization
# cleaning video titles
videos_year$title= gsub("<.*?>","", videos_year$title) #removing html tags
videos_year$title= gsub("[[:punct:]]", " ", videos_year$title) #removing html tags
videos_year$title = gsub("[ |\t]{2,}", " ", videos_year$title)  # Remove tabs
videos_year$title = gsub("^ ", "", videos_year$title)  # Leading blanks
videos_year$title = gsub(" $", "", videos_year$title)  # Lagging blanks
videos_year$title = gsub(" +", " ", videos_year$title) # General spaces
videos_year$title = tolower(videos_year$title) # lowering all letters
write.csv(videos_year,'dog.csv', row.names = FALSE)
videos_year <- yt_search(term = "pets")
videostats = lapply(as.character(videos_year$video_id), function(x){
get_stats(video_id = x)
})
library(tuber)
app_id = '570143920296-d6n69c7bm713edtm3vffmtq46t0751pm.apps.googleusercontent.com'
app_secret = 'DB27e-L6XpKcAOx6UyK1hv0i'
# establishing connecting with YouTube
# credentials
yt_oauth(app_id = app_id, app_secret = app_secret)
videos_year <- yt_search(term = "pets")
videostats = lapply(as.character(videos_year$video_id), function(x){
get_stats(video_id = x)
})
library(plyr)
df = ldply(videostats, data.frame)
# merging videos stats with the main file:  videos_year
colnames(df)[1] = 'video_id' # renaming 'id' as video_id so that it matches same coluimn in main table
library(dplyr)
videos_year = videos_year %>% left_join(df, by = 'video_id')
# correcting data type
videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')]=apply(videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')],2,as.numeric)
# converting into data type 'date'
videos_year$publishedAt = as.Date(videos_year$publishedAt)
str(videos_year$publishedAt)
#install.packages("lubridate")
library(lubridate)
# creating new variables 'year' and 'month'
videos_year = videos_year %>% mutate(month = month(publishedAt)) %>% mutate(year = year(publishedAt))
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
#install.packages("factoextra")
library(factoextra) # clustering algorithms & visualization
# cleaning video titles
videos_year$title= gsub("<.*?>","", videos_year$title) #removing html tags
videos_year$title= gsub("[[:punct:]]", " ", videos_year$title) #removing html tags
videos_year$title = gsub("[ |\t]{2,}", " ", videos_year$title)  # Remove tabs
videos_year$title = gsub("^ ", "", videos_year$title)  # Leading blanks
videos_year$title = gsub(" $", "", videos_year$title)  # Lagging blanks
videos_year$title = gsub(" +", " ", videos_year$title) # General spaces
videos_year$title = tolower(videos_year$title) # lowering all letters
write.csv(videos_year,'pets.csv', row.names = FALSE)
videos_year <- yt_search(term = "cute animals")
videostats = lapply(as.character(videos_year$video_id), function(x){
get_stats(video_id = x)
})
library(plyr)
df = ldply(videostats, data.frame)
# merging videos stats with the main file:  videos_year
colnames(df)[1] = 'video_id' # renaming 'id' as video_id so that it matches same coluimn in main table
library(dplyr)
videos_year = videos_year %>% left_join(df, by = 'video_id')
# correcting data type
videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')]=apply(videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')],2,as.numeric)
# converting into data type 'date'
videos_year$publishedAt = as.Date(videos_year$publishedAt)
str(videos_year$publishedAt)
#install.packages("lubridate")
library(lubridate)
# creating new variables 'year' and 'month'
videos_year = videos_year %>% mutate(month = month(publishedAt)) %>% mutate(year = year(publishedAt))
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
#install.packages("factoextra")
library(factoextra) # clustering algorithms & visualization
# cleaning video titles
videos_year$title= gsub("<.*?>","", videos_year$title) #removing html tags
videos_year$title= gsub("[[:punct:]]", " ", videos_year$title) #removing html tags
videos_year$title = gsub("[ |\t]{2,}", " ", videos_year$title)  # Remove tabs
videos_year$title = gsub("^ ", "", videos_year$title)  # Leading blanks
videos_year$title = gsub(" $", "", videos_year$title)  # Lagging blanks
videos_year$title = gsub(" +", " ", videos_year$title) # General spaces
videos_year$title = tolower(videos_year$title) # lowering all letters
write.csv(videos_year,'cute_animals.csv', row.names = FALSE)
videos_year <- yt_search(term = "cutest puppies")
videostats = lapply(as.character(videos_year$video_id), function(x){
get_stats(video_id = x)
})
library(plyr)
df = ldply(videostats, data.frame)
# merging videos stats with the main file:  videos_year
colnames(df)[1] = 'video_id' # renaming 'id' as video_id so that it matches same coluimn in main table
library(dplyr)
videos_year = videos_year %>% left_join(df, by = 'video_id')
# correcting data type
videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')]=apply(videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')],2,as.numeric)
# converting into data type 'date'
videos_year$publishedAt = as.Date(videos_year$publishedAt)
str(videos_year$publishedAt)
#install.packages("lubridate")
library(lubridate)
# creating new variables 'year' and 'month'
videos_year = videos_year %>% mutate(month = month(publishedAt)) %>% mutate(year = year(publishedAt))
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
#install.packages("factoextra")
library(factoextra) # clustering algorithms & visualization
# cleaning video titles
videos_year$title= gsub("<.*?>","", videos_year$title) #removing html tags
videos_year$title= gsub("[[:punct:]]", " ", videos_year$title) #removing html tags
videos_year$title = gsub("[ |\t]{2,}", " ", videos_year$title)  # Remove tabs
videos_year$title = gsub("^ ", "", videos_year$title)  # Leading blanks
videos_year$title = gsub(" $", "", videos_year$title)  # Lagging blanks
videos_year$title = gsub(" +", " ", videos_year$title) # General spaces
videos_year$title = tolower(videos_year$title) # lowering all letters
write.csv(videos_year,'cutest_puppies.csv', row.names = FALSE)
videos_year <- yt_search(term = "animal")
library(tuber)
app_id = '637343645099-ngdppd65ohdecs5lp4utoch48utr0nhv.apps.googleusercontent.com'
app_secret = 'WqQpVU82xWuEp8MizGmHg69u'
# establishing connecting with YouTube
# credentials
yt_oauth(app_id = app_id, app_secret = app_secret)
videos_year <- yt_search(term = "animal")
videostats = lapply(as.character(videos_year$video_id), function(x){
get_stats(video_id = x)
})
library(plyr)
df = ldply(videostats, data.frame)
# merging videos stats with the main file:  videos_year
colnames(df)[1] = 'video_id' # renaming 'id' as video_id so that it matches same coluimn in main table
library(dplyr)
videos_year = videos_year %>% left_join(df, by = 'video_id')
# correcting data type
videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')]=apply(videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')],2,as.numeric)
# converting into data type 'date'
videos_year$publishedAt = as.Date(videos_year$publishedAt)
str(videos_year$publishedAt)
#install.packages("lubridate")
library(lubridate)
# creating new variables 'year' and 'month'
videos_year = videos_year %>% mutate(month = month(publishedAt)) %>% mutate(year = year(publishedAt))
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
#install.packages("factoextra")
library(factoextra) # clustering algorithms & visualization
# cleaning video titles
videos_year$title= gsub("<.*?>","", videos_year$title) #removing html tags
videos_year$title= gsub("[[:punct:]]", " ", videos_year$title) #removing html tags
videos_year$title = gsub("[ |\t]{2,}", " ", videos_year$title)  # Remove tabs
videos_year$title = gsub("^ ", "", videos_year$title)  # Leading blanks
videos_year$title = gsub(" $", "", videos_year$title)  # Lagging blanks
videos_year$title = gsub(" +", " ", videos_year$title) # General spaces
videos_year$title = tolower(videos_year$title) # lowering all letters
write.csv(videos_year,'animal.csv', row.names = FALSE)
videos_year <- yt_search(term = "pet")
videostats = lapply(as.character(videos_year$video_id), function(x){
get_stats(video_id = x)
})
library(plyr)
df = ldply(videostats, data.frame)
# merging videos stats with the main file:  videos_year
colnames(df)[1] = 'video_id' # renaming 'id' as video_id so that it matches same coluimn in main table
library(dplyr)
videos_year = videos_year %>% left_join(df, by = 'video_id')
# correcting data type
videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')]=apply(videos_year[,c('viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount')],2,as.numeric)
# converting into data type 'date'
videos_year$publishedAt = as.Date(videos_year$publishedAt)
str(videos_year$publishedAt)
#install.packages("lubridate")
library(lubridate)
# creating new variables 'year' and 'month'
videos_year = videos_year %>% mutate(month = month(publishedAt)) %>% mutate(year = year(publishedAt))
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
#install.packages("factoextra")
library(factoextra) # clustering algorithms & visualization
# cleaning video titles
videos_year$title= gsub("<.*?>","", videos_year$title) #removing html tags
videos_year$title= gsub("[[:punct:]]", " ", videos_year$title) #removing html tags
videos_year$title = gsub("[ |\t]{2,}", " ", videos_year$title)  # Remove tabs
videos_year$title = gsub("^ ", "", videos_year$title)  # Leading blanks
videos_year$title = gsub(" $", "", videos_year$title)  # Lagging blanks
videos_year$title = gsub(" +", " ", videos_year$title) # General spaces
videos_year$title = tolower(videos_year$title) # lowering all letters
write.csv(videos_year,'pet.csv', row.names = FALSE)
videos_year <- yt_search(term = "pets dogs")
videostats = lapply(as.character(videos_year$video_id), function(x){
get_stats(video_id = x)
})
