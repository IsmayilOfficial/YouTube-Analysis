clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
xx<- read.csv("cooking_comments.csv")
xx<- read.csv("cooking_comments.csv")
zaz<- xx$comment
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
# using sentiment package to classify polarities
polarities = classify_polarity(clean_tweets, algorithm='bayes')
df = data.frame(text=clean_tweets, emotion=emotions[,'BEST_FIT'],
polarity=polarities[,'BEST_FIT'], stringsAsFactors=FALSE)
df<- na.omit(df)
df[is.na(df)] <- "N.A."
# plot the emotions
plot_ly(df, x=~emotion,type="histogram",
marker = list(color = c('grey', 'red',
'orange', 'navy',
'yellow'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Emotions")
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
# using sentiment package to classify polarities
polarities = classify_polarity(clean_tweets, algorithm='bayes')
df = data.frame(text=clean_tweets, emotion=emotions[,'BEST_FIT'],
polarity=polarities[,'BEST_FIT'], stringsAsFactors=FALSE)
df<- na.omit(df)
df[is.na(df)] <- "N.A."
plot_ly(df, x=~polarity, type="histogram",
marker = list(color = c('magenta', 'gold',
'lightblue'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Polarity")
# Visualize the words by polarity
df <- df %>%
group_by(polarity) %>%
summarise(pasted=paste(text, collapse=" "))
# remove stopwords
df$pasted = removeWords(df$pasted, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(df$pasted))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = df$polarity
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(3, 'Dark2'),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
xx<- read.csv("music.csv")
xx<- read.csv("music.csv")
zaz<- xx$comment_text
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
# using sentiment package to classify polarities
polarities = classify_polarity(clean_tweets, algorithm='bayes')
df = data.frame(text=clean_tweets, emotion=emotions[,'BEST_FIT'],
polarity=polarities[,'BEST_FIT'], stringsAsFactors=FALSE)
df<- na.omit(df)
df[is.na(df)] <- "N.A."
plot_ly(df, x=~polarity, type="histogram",
marker = list(color = c('magenta', 'gold',
'lightblue'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Polarity")
# Visualize the words by polarity
df <- df %>%
group_by(polarity) %>%
summarise(pasted=paste(text, collapse=" "))
# remove stopwords
df$pasted = removeWords(df$pasted, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(df$pasted))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = df$polarity
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(3, 'Dark2'),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
xx<- read.csv("Gaming_comments.csv")
zaz<- xx$comment_text
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
xx<- read.csv("Gaming_comments.csv")
zaz<- xx$comment
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
# using sentiment package to classify polarities
polarities = classify_polarity(clean_tweets, algorithm='bayes')
df = data.frame(text=clean_tweets, emotion=emotions[,'BEST_FIT'],
polarity=polarities[,'BEST_FIT'], stringsAsFactors=FALSE)
df<- na.omit(df)
df[is.na(df)] <- "N.A."
plot_ly(df, x=~polarity, type="histogram",
marker = list(color = c('magenta', 'gold',
'lightblue'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Polarity")
# Visualize the words by polarity
df <- df %>%
group_by(polarity) %>%
summarise(pasted=paste(text, collapse=" "))
# remove stopwords
df$pasted = removeWords(df$pasted, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(df$pasted))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = df$polarity
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(3, 'Dark2'),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
xx<- read.csv("movies.csv")
xx<- read.csv("movies.csv")
zaz<- xx$comment_text
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
# using sentiment package to classify polarities
polarities = classify_polarity(clean_tweets, algorithm='bayes')
df = data.frame(text=clean_tweets, emotion=emotions[,'BEST_FIT'],
polarity=polarities[,'BEST_FIT'], stringsAsFactors=FALSE)
df<- na.omit(df)
df[is.na(df)] <- "N.A."
xx<- read.csv("movies.csv")
zaz<- xx$comment_text
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
# using sentiment package to classify polarities
polarities = classify_polarity(clean_tweets, algorithm='bayes')
df = data.frame(text=clean_tweets, emotion=emotions[,'BEST_FIT'],
polarity=polarities[,'BEST_FIT'], stringsAsFactors=FALSE)
df<- na.omit(df)
df[is.na(df)] <- "N.A."
# plot the emotions
plot_ly(df, x=~emotion,type="histogram",
marker = list(color = c('grey', 'red',
'orange', 'navy',
'yellow'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Emotions")
plot_ly(df, x=~polarity, type="histogram",
marker = list(color = c('magenta', 'gold',
'lightblue'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Polarity")
xx<- read.csv("Pets&AnimalsComments.csv")
zaz<- xx$comment_text
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
xx<- read.csv("Pets&AnimalsComments.csv")
zaz<- xx$Comments
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
# using sentiment package to classify polarities
polarities = classify_polarity(clean_tweets, algorithm='bayes')
df = data.frame(text=clean_tweets, emotion=emotions[,'BEST_FIT'],
polarity=polarities[,'BEST_FIT'], stringsAsFactors=FALSE)
df<- na.omit(df)
df[is.na(df)] <- "N.A."
# plot the emotions
plot_ly(df, x=~emotion,type="histogram",
marker = list(color = c('grey', 'red',
'orange', 'navy',
'yellow'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Emotions")
plot_ly(df, x=~polarity, type="histogram",
marker = list(color = c('magenta', 'gold',
'lightblue'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Polarity")
# Visualize the words by polarity
df <- df %>%
group_by(polarity) %>%
summarise(pasted=paste(text, collapse=" "))
# remove stopwords
df$pasted = removeWords(df$pasted, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(df$pasted))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = df$polarity
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(3, 'Dark2'),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
xx<- read.csv("S&TComments.csv")
xx<- read.csv("S&TComments.csv")
xx<- read.csv("S&TComments.csv")
zaz<- xx$Comments
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
xx<- read.csv("S&TComments.csv")
zaz<- xx$Comment
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
xx<- read.csv("S&TComments.csv")
zaz<- xx$comment
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
# using sentiment package to classify polarities
polarities = classify_polarity(clean_tweets, algorithm='bayes')
df = data.frame(text=clean_tweets, emotion=emotions[,'BEST_FIT'],
polarity=polarities[,'BEST_FIT'], stringsAsFactors=FALSE)
df<- na.omit(df)
df[is.na(df)] <- "N.A."
# plot the emotions
plot_ly(df, x=~emotion,type="histogram",
marker = list(color = c('grey', 'red',
'orange', 'navy',
'yellow'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Emotions")
plot_ly(df, x=~polarity, type="histogram",
marker = list(color = c('magenta', 'gold',
'lightblue'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Polarity")
# Visualize the words by polarity
df <- df %>%
group_by(polarity) %>%
summarise(pasted=paste(text, collapse=" "))
# remove stopwords
df$pasted = removeWords(df$pasted, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(df$pasted))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = df$polarity
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(3, 'Dark2'),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
xx<- read.csv("sport_comments.csv")
zaz<- xx$comment
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
# using sentiment package to classify polarities
polarities = classify_polarity(clean_tweets, algorithm='bayes')
df = data.frame(text=clean_tweets, emotion=emotions[,'BEST_FIT'],
polarity=polarities[,'BEST_FIT'], stringsAsFactors=FALSE)
df<- na.omit(df)
df[is.na(df)] <- "N.A."
# plot the emotions
plot_ly(df, x=~emotion,type="histogram",
marker = list(color = c('grey', 'red',
'orange', 'navy',
'yellow'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Emotions")
plot_ly(df, x=~polarity, type="histogram",
marker = list(color = c('magenta', 'gold',
'lightblue'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Polarity")
# Visualize the words by polarity
df <- df %>%
group_by(polarity) %>%
summarise(pasted=paste(text, collapse=" "))
# remove stopwords
df$pasted = removeWords(df$pasted, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(df$pasted))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = df$polarity
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(3, 'Dark2'),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
xx<- read.csv("travel_comments.csv")
zaz<- xx$comment
zaz<- na.omit(zaz)
clean_tweets<-zaz
# using sentiment package to classify emotions
emotions <- classify_emotion(clean_tweets, algorithm='bayes')
# using sentiment package to classify polarities
polarities = classify_polarity(clean_tweets, algorithm='bayes')
df = data.frame(text=clean_tweets, emotion=emotions[,'BEST_FIT'],
polarity=polarities[,'BEST_FIT'], stringsAsFactors=FALSE)
df<- na.omit(df)
df[is.na(df)] <- "N.A."
# plot the emotions
plot_ly(df, x=~emotion,type="histogram",
marker = list(color = c('grey', 'red',
'orange', 'navy',
'yellow'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Emotions")
plot_ly(df, x=~polarity, type="histogram",
marker = list(color = c('magenta', 'gold',
'lightblue'))) %>%
layout(yaxis = list(title='Count'), title="Sentiment Analysis: Polarity")
# Visualize the words by polarity
df <- df %>%
group_by(polarity) %>%
summarise(pasted=paste(text, collapse=" "))
# remove stopwords
df$pasted = removeWords(df$pasted, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(df$pasted))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = df$polarity
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(3, 'Dark2'),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
knitr::opts_chunk$set(echo = TRUE)
library(tuber)
app_id = '570143920296-d6n69c7bm713edtm3vffmtq46t0751pm.apps.googleusercontent.com'
app_secret = 'DB27e-L6XpKcAOx6UyK1hv0i'
# establishing connecting with YouTube
# credentials
yt_oauth(app_id = app_id, app_secret = app_secret)
# Category IDs
# 1 -> Film & Animation
# 10 -> Music
# 17 -> Sports
# 26 -> Howto & Style
for(j in c(1, 10, 17, 26)){
# Get list of top 50 videos in US region in the selected category
video_list <- list_videos(max_results = 50, region_code = "US", video_category_id = j)
# Get a list of Video ID's in the Category which have less than 10000 comments each
video_id <- c()
for(i in 1:length(video_list$items)){
video_stats <- get_stats(video_id = video_list$items[[i]]$id)
count <- video_stats$commentCount
if(!is.null(count)){
if(as.numeric(count) < 10000){
video_id <- c(video_id, video_list$items[[i]]$id)
}
}
}
# Create a data frame with all the comments combined for the selected Video ID's in the Category
comments <- c()
for(i in 1:length(video_id)){
comments <- rbind(comments
, get_comment_threads(c(video_id = video_id[i]), max_results = 101)[, 1:12]
, method="common")
}
# Pick 50k rows
comments <- comments[1:50000,]
# Save the results in CSV files
if(j == 1)
write.csv(comments, "animation_video_comments.csv")
if(j == 10)
write.csv(comments, "music_video_comments.csv")
if(j == 17)
write.csv(comments, "sports_video_comments.csv")
if(j == 26)
write.csv(comments, "howto_video_comments.csv")
}
knitr::opts_chunk$set(echo = TRUE)
library(tuber)
app_id = '637343645099-ngdppd65ohdecs5lp4utoch48utr0nhv.apps.googleusercontent.com'
app_secret = 'WqQpVU82xWuEp8MizGmHg69u'
# establishing connecting with YouTube
# credentials
yt_oauth(app_id = app_id, app_secret = app_secret)
for(j in c(1, 10, 17, 26)){
# Get list of top 50 videos in US region in the selected category
video_list <- list_videos(max_results = 50, region_code = "US", video_category_id = j)
# Get a list of Video ID's in the Category which have less than 10000 comments each
video_id <- c()
for(i in 1:length(video_list$items)){
video_stats <- get_stats(video_id = video_list$items[[i]]$id)
count <- video_stats$commentCount
if(!is.null(count)){
if(as.numeric(count) < 10){
video_id <- c(video_id, video_list$items[[i]]$id)
}
}
}
# Create a data frame with all the comments combined for the selected Video ID's in the Category
comments <- c()
for(i in 1:length(video_id)){
comments <- rbind(comments
, get_comment_threads(c(video_id = video_id[i]), max_results = 101)[, 1:12]
, method="common")
}
# Pick 50k rows
comments <- comments[1:50000,]
# Save the results in CSV files
if(j == 1)
write.csv(comments, "animation_video_comments.csv")
if(j == 10)
write.csv(comments, "music_video_comments.csv")
if(j == 17)
write.csv(comments, "sports_video_comments.csv")
if(j == 26)
write.csv(comments, "howto_video_comments.csv")
}
knitr::opts_chunk$set(echo = TRUE)
x1<- read.csv("Comedy.csv")
x1<- read.csv("ComedyUS.csv")
x<-rbind(x1,x2)
x1<- read.csv("Comedy.csv")
x2<- read.csv("ComedyUS.csv")
x<-rbind(x1,x2)
x1<- read.csv("Comedy.csv")
x2<- read.csv("ComedyUS.csv")
x3<- read.csv("comedy_sketch.csv")
x<-rbind(x1,x2,x3)
x1<- read.csv("Comedy.csv")
x2<- read.csv("ComedyUS.csv")
x3<- read.csv("comedy_sketch.csv")
x4<- read.csv("comedy_sketch1.csv")
x<-rbind(x1,x2,x3,x4)
x1<- read.csv("Comedy.csv")
x2<- read.csv("ComedyUS.csv")
x3<- read.csv("comedy_sketch.csv")
x4<- read.csv("comedy_sketch1.csv")
x5<- read.csv("ComedyUK.csv")
x<-rbind(x1,x2,x3,x4,x5)
x1<- read.csv("Comedy.csv")
x2<- read.csv("ComedyUS.csv")
x3<- read.csv("comedy_sketch.csv")
x4<- read.csv("comedy_sketch1.csv")
x5<- read.csv("ComedyUK.csv")
x6<- read.csv("rowanAtkinson.csv")
x6<- read.csv("stand_up.csv")
x<-rbind(x1,x2,x3,x4,x5,x6,x7)
x1<- read.csv("Comedy.csv")
x2<- read.csv("ComedyUS.csv")
x3<- read.csv("comedy_sketch.csv")
x4<- read.csv("comedy_sketch1.csv")
x5<- read.csv("ComedyUK.csv")
x6<- read.csv("rowanAtkinson.csv")
x7<- read.csv("stand_up.csv")
x<-rbind(x1,x2,x3,x4,x5,x6,x7)
write.csv(x,"ALLComedy.csv")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
#videos<-read.csv("movies_duration.csv")
dat<- read.csv('ALLComedy.csv')
#dat<- rbind(videos,dat)
#write.csv(dat,"Film&Animation.csv")
dat <- na.omit(dat)
View(dat)
cor(dat$viewCount,dat$likeCount,method = "pearson")
## Basic histogram from the vector "rating". Each bin is .5 wide.
## These both result in the same output:
#ggplot(dat, aes(x=duration)) + geom_histogram(binwidth=.5)
# # # qplot(dat$rating, binwidth=.5)
# #
# # # Draw with black outline, white fill
#  ggplot(dat, aes(x=duration)) +
#     geom_histogram(binwidth=.5, colour="black", fill="white")
# Density curve
ggplot(dat, aes(x=duration)) + geom_density()
knitr::opts_chunk$set(echo = TRUE)
va<- read.csv("title_length_ans.csv")
va<- na.omit(va)
M<-cor(va)
head(round(M,2))
library(corrplot)
# method = "pie"
corrplot(M, method = "pie")
# method = "pie"
corrplot(M, method = "heatmap")
# method = "pie"
corrplot(M, method = "color")
library("tm")
library("SnowballC")
posts<- read.csv("ALLComedy.csv", header = TRUE,  fileEncoding="latin1")
corpus <- Corpus(VectorSource(posts$title)) # create corpus object
corpus <- tm_map(corpus, tolower) # convert all text to lower case
corpus <- tm_map(corpus, mc.cores=1, removePunctuation)
corpus <- tm_map(corpus, removeNumbers, mc.cores=1)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
tdm <- TermDocumentMatrix(corpus)
#tdm <- TermDocumentMatrix(corpus, control = list(weighting = weightTfIdf))
mydata.df <- as.data.frame(inspect(tdm))
count<- as.data.frame(rowSums(mydata.df))
count$word = rownames(count)
colnames(count) <- c("count","word" )
count<-count[order(count$count, decreasing=TRUE), ]
View(count)
write.csv(count,"PTT.csv")
x<- read.csv("ALLComedy.csv")
library(stringr)
description_length<- str_count(x$description, '\\w+')
ca <- as.data.frame(description_length)
write.csv(ca,"xama.csv")
x<- read.csv("ALLComedy.csv")
library(stringr)
description_length<- str_count(x$title, '\\w+')
ca <- as.data.frame(title length)
x<- read.csv("ALLComedy.csv")
library(stringr)
description_length<- str_count(x$title, '\\w+')
ca <- as.data.frame(title_length)
x<- read.csv("ALLComedy.csv")
library(stringr)
title_length<- str_count(x$title, '\\w+')
ca <- as.data.frame(title_length)
write.csv(ca,"xama.csv")
write.csv(ca,"xama.csv")
va<- read.csv("ComedyCorrelation.csv")
va<- na.omit(va)
M<-cor(va)
head(round(M,2))
library(corrplot)
# method = "pie"
corrplot(M, method = "color")
